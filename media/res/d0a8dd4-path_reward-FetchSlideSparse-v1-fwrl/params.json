{"max_u": 1.0, "layers": 3, "hidden": 256, "network_class": "baselines.her.actor_critic:ActorCritic", "Q_lr": 0.001, "pi_lr": 0.001, "buffer_size": 1000000, "polyak": 0.95, "action_l2": 1.0, "clip_obs": 200.0, "scope": "ddpg", "relative_goals": false, "n_cycles": 50, "rollout_batch_size": 2, "n_batches": 40, "batch_size": 256, "n_test_rollouts": 10, "test_with_polyak": false, "random_eps": 0.3, "noise_eps": 0.2, "replay_strategy": "future", "replay_k": 4, "norm_eps": 0.01, "norm_clip": 5, "loss_term": "fwrl", "user": "dhiman", "mid_dir": "/z/home/dhiman/mid", "project_name": "floyd-warshall-rl/openai-baselines/her", "gitrev": "d0a8dd4", "env": "FetchSlideSparse-v1", "hash_params": "3a5d41b1", "env_name": "FetchSlideSparse-v1", "logdir": "/z/home/dhiman/mid/floyd-warshall-rl/openai-baselines/her/d0a8dd4-path_reward-FetchSlideSparse-v1-fwrl", "n_epochs": 200, "seed": 0, "policy_save_interval": 5, "clip_return": true, "intermediate_sampling": "uniform", "exp_name": "path_reward-FetchSlideSparse-v1-fwrl", "recompute_rewards": true, "distance_threshold": 0.05, "loss_term_weights_json": "[]", "loss_term_weights": []}