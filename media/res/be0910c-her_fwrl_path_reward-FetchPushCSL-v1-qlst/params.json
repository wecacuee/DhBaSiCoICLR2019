{"max_u": 1.0, "layers": 3, "hidden": 256, "network_class": "baselines.her.actor_critic:ActorCritic", "Q_lr": 0.001, "pi_lr": 0.001, "buffer_size": 1000000, "polyak": 0.95, "action_l2": 1.0, "clip_obs": 200.0, "scope": "ddpg", "relative_goals": false, "n_cycles": 50, "rollout_batch_size": 2, "n_batches": 40, "batch_size": 256, "n_test_rollouts": 10, "test_with_polyak": false, "random_eps": 0.3, "noise_eps": 0.2, "replay_strategy": "future", "replay_k": 4, "norm_eps": 0.01, "norm_clip": 5, "loss_term": "qlst", "user": "dhiman", "mid_dir": "/z/home/dhiman/mid", "project_name": "floyd-warshall-rl/openai-baselines/her", "gitrev": "be0910c", "env": "FetchPushCSL-v1", "hash_params": "fa41d9a8", "env_name": "FetchPushCSL-v1", "logdir": "/z/home/dhiman/mid/floyd-warshall-rl/openai-baselines/her/be0910c-her_fwrl_path_reward-FetchPushCSL-v1-qlst", "n_epochs": 30, "seed": 0, "policy_save_interval": 5, "clip_return": true, "intermediate_sampling": "uniform", "exp_name": "her_fwrl_path_reward-FetchPushCSL-v1-qlst", "recompute_rewards": true, "loss_term_weights_json": "[]", "loss_term_weights": []}