\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{MnKaSiNATURE2015}
\citation{gibney2016google}
\citation{anderson2017vision}
\@writefile{toc}{\contentsline {section}{\numberline {1} Introduction}{1}{section.1}}
\citation{pong2018temporal}
\citation{andrychowicz2016learning}
\citation{schaul2015universal}
\citation{schaul2015universal}
\citation{andrychowicz2016learning}
\citation{pong2018temporal}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Goal-conditioned value functions}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Combining model-based and model-free methods}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Navigation with mapping}{2}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Model free DRL }{2}{subsection.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Model based DRL}{2}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Multi-goal navigation based papers}{2}{subsection.2.6}}
\citation{dijkstra1959note}
\citation{watkins1992qlearning}
\citation{floydwarshall1962}
\citation{johnson1977efficient}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dijkstra}{3}{subsection.3.1}}
\newlabel{eq:dijkstra}{{1}{3}{Dijkstra}{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Q-Learning}{3}{subsection.3.2}}
\newlabel{eq:q-learn-bellman}{{2}{3}{Q-Learning}{equation.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Floyd-Warshall}{3}{subsection.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Problem definition}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Environment Setup}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Why is this problem important?}{4}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Why is the problem hard?}{4}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Method}{4}{section.5}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{10}\selectfont  Floyd-Warshall Reinforcement Learning (Tabular setting)}}{4}{algocf.1}}
\newlabel{alg:floyd-warshall-small}{{1}{4}{Method}{algocf.1}{}}
\citation{}
\citation{MiPaViICLR2017}
\citation{dhiman2018critical}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments}{5}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Four room grid world}{5}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Four room windy world}{5}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Random Grid Worlds}{5}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Metrics}{5}{subsection.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Left: Four room grid world. Right: Four room windy grid world with wind direction shown by arrows. The windy pushes the agent in the direction of wind with 0.25 probability irrespective of the action taken.}}{5}{figure.1}}
\newlabel{fig:four-room-grid-world}{{1}{5}{Left: Four room grid world. Right: Four room windy grid world with wind direction shown by arrows. The windy pushes the agent in the direction of wind with 0.25 probability irrespective of the action taken}{figure.1}{}}
\citation{MiPaViICLR2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Results on grid world. FWRL beats Q-Learning consistently. Higher is better in both the metrics (higher is better).}}{6}{figure.2}}
\newlabel{fig:ql-fw-grid-world-results}{{2}{6}{Results on grid world. FWRL beats Q-Learning consistently. Higher is better in both the metrics (higher is better)}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Results on windy world. FWRL beats Q-Learning consistently. Higher is better in both the metrics (higher is better).}}{6}{figure.3}}
\newlabel{fig:ql-fw-windy-world-results}{{3}{6}{Results on windy world. FWRL beats Q-Learning consistently. Higher is better in both the metrics (higher is better)}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Results}{6}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Conclusion}{6}{subsection.7.1}}
\citation{schaul2015universal}
\bibdata{main,main_filtered}
\bibstyle{aaai}
